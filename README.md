# Detecting the Higgs Boson with TPUs

This project demonstrates an improved approach to classifying Higgs boson events using a modern Wide & Deep neural network. It leverages modern Keras practices, feature normalization, and enhanced training stability for high-performance classification on the Higgs Boson dataset.

The model is designed to run efficiently on Google's Tensor Processing Units (TPUs) but also supports GPU and CPU execution.

## Key Features

- **Modern Wide & Deep Architecture**: Built with the Keras Functional API, combining the strengths of memorization (wide component) and generalization (deep component).
- **Input Normalization**: A `Normalization` layer is adapted on a sample of the training data and integrated directly into the model, ensuring consistent feature scaling.
- **Enhanced Callbacks**: Implements a robust callback suite for stable training:
  - `EarlyStopping` based on `val_AUC` to prevent overfitting and save time.
  - `ReduceLROnPlateau` to dynamically adjust the learning rate.
  - `ModelCheckpoint` to save the best-performing model during training.
- **Regularization**: L2 regularization is added to the deep layers to reduce overfitting.
- **Efficient Data Pipeline**: Uses `tf.data` and `TFRecord` for a highly efficient, parallelized input pipeline suitable for large datasets and TPUs.

## Prerequisites

This project requires Python 3.x and the following libraries. You can install them using pip:

```shell
pip install tensorflow pandas numpy matplotlib seaborn
```

## Getting Started

1.  **Clone the repository:**
    ```shell
    git clone <your-repository-url>
    cd <your-repository-name>
    ```
2.  **Environment**: For best performance, run the notebook in an environment with TPU or GPU access, such as Kaggle Kernels or Google Colab. The code will automatically fall back to a CPU if a dedicated accelerator is not found.
3.  **Dataset**: The notebook is configured to automatically download and use the public "Higgs Boson" dataset from Kaggle's GCS buckets. No manual download is required if you are in a Kaggle environment.
4.  **Execution**: Open and run the cells in the `detecting-the-higgs-boson-with-tpus-3ea1ef.ipynb` notebook sequentially.

## Model Architecture

The model implements a Wide & Deep architecture. The diagram below is generated by the notebook.


## Results

The model achieves a validation AUC of approximately **0.864**, demonstrating a strong ability to distinguish signal from background events. The training process is automatically managed by callbacks to ensure efficiency and prevent overfitting.

The training history graphs below are generated by the notebook 
<img width="1124" height="449" alt="image" src="https://github.com/user-attachments/assets/8dc61659-4f43-4866-8a8b-c7569a4cae60" />
<img width="1121" height="461" alt="image" src="https://github.com/user-attachments/assets/20010525-68c6-4296-8df2-cc5705117242" />


### Output Artifacts

After a successful run, the notebook will generate several files. Ensure `wide_and_deep_model.png` and `training_history.png` are committed to your repository for the images above to display correctly.

- `best_higgs_model.keras`: The model file with the best weights.
- `final_higgs_model.keras`: The final state of the model.
- `training_history.csv`: A CSV file with the loss and metrics for each epoch.
- `training_history.png`: The visualization of training curves shown above.
- `model_config.json`: A JSON file summarizing the model's configuration and performance.
- `wide_and_deep_model.png`: The model architecture diagram shown above.
